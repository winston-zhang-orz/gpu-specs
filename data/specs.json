{
  "_header": {
    "name": { "full_name": "GPU Name" },
    "fp64": { "full_name": "FP64", "unit": "TFLOPS" },
    "fp64_tensor_core": { "full_name": "FP64 Tensor Core", "unit": "TFLOPS" },
    "fp32": { "full_name": "FP32", "unit": "TFLOPS" },
    "tf32_tensor_core": { "full_name": "TF32 Tensor Core", "unit": "TFLOPS" },
    "tf32_tensor_core_sparsity": { "full_name": "TF32 Tensor Core with Sparsity", "unit": "TFLOPS" },
    "fp16": { "full_name": "FP16", "unit": "TFLOPS" },
    "fp16_tensor_core": { "full_name": "FP16 Tensor Core", "unit": "TFLOPS" },
    "fp16_tensor_core_sparsity": { "full_name": "FP16 Tensor Core with Sparsity", "unit": "TFLOPS" },
    "bf16": { "full_name": "BF16", "unit": "TFLOPS" },
    "bf16_tensor_core": { "full_name": "BF16 Tensor Core", "unit": "TFLOPS" },
    "bf16_tensor_core_sparsity": { "full_name": "BF16 Tensor Core with Sparsity", "unit": "TFLOPS" },
    "fp8": { "full_name": "FP8", "unit": "TFLOPS" },
    "fp8_tensor_core": { "full_name": "FP8 Tensor Core", "unit": "TFLOPS" },
    "fp8_tensor_core_sparsity": { "full_name": "FP8 Tensor Core with Sparsity", "unit": "TFLOPS" },
    "fp4": { "full_name": "FP4", "unit": "TFLOPS" },
    "fp4_tensor_core": { "full_name": "FP4 Tensor Core", "unit": "TFLOPS" },
    "int8": { "full_name": "INT8", "unit": "TOPS" },
    "int8_tensor_core": { "full_name": "INT8 Tensor Core", "unit": "TOPS" },
    "int8_tensor_core_sparsity": { "full_name": "INT8 Tensor Core with Sparsity", "unit": "TOPS" },
    "int4": { "full_name": "INT4", "unit": "TOPS" },
    "int4_tensor_core": { "full_name": "INT4 Tensor Core", "unit": "TOPS" },
    "int4_tensor_core_sparsity": { "full_name": "INT4 Tensor Core with Sparsity", "unit": "TOPS" },
    "manufacturer": { "full_name": "Manufacturer" },
    "architecture": { "full_name": "Architecture" },
    "nvidia_rt_cores": { "full_name": "NVIDIA RT Cores"},
    "nvidia_rt_cores_generation": { "full_name": "NVIDIA RT Cores Generation"},
    "nvidia_tensor_cores": { "full_name": "NVIDIA Tensor Cores" },
    "nvidia_tensor_cores_generation": { "full_name": "NVIDIA Tensor Cores Generation" },
    "nvidia_cuda_cores": { "full_name": "NVIDIA CUDA Cores" },
    "gpu_memory": { "full_name": "GPU Memory", "unit": "GB" },
    "memory_bandwidth": { "full_name": "Memory Bandwidth", "unit": "GB/s" },
    "interconnect": { "full_name": "Interconnect Type" },
    "encoders_decoders": { "full_name": "Encoders and Decoders" },
    "cuda_compute_capability": { "full_name": "CUDA Compute Capability" },
    "power_consumption": { "full_name": "Power Consumption", "unit": "W" }
   },
   "B100": {
      "name": "B100",
      "fp64": 25.6,
      "fp64_tensor_core": 51,
      "fp32": 51.2,
      "tf32_tensor_core": null,
      "tf32_tensor_core_sparsity": 756,
      "fp16": 204.9,
      "fp16_tensor_core": null,
      "fp16_tensor_core_sparsity": null,
      "bf16": null,
      "bf16_tensor_core": null,
      "bf16_tensor_core_sparsity": 1513,
      "fp8": 0,
      "fp8_tensor_core": null,
      "fp4": 0,
      "fp4_tensor_core": 0,
      "fp8_tensor_core_sparsity": 3026,
      "int8": null,
      "int8_tensor_core": null,
      "int8_tensor_core_sparsity": 3026,
      "int4": 0,
      "int4_tensor_core": 1,
      "int4_tensor_core_sparsity": null,
      "manufacturer": "NVIDIA",
      "architecture": "Hopper",
      "nvidia_rt_cores": null,
      "nvidia_rt_cores_generation": null,
      "nvidia_tensor_cores": 456,
      "nvidia_tensor_cores_generation": 4,
      "nvidia_cuda_cores": 14592,
      "gpu_memory": 80,
      "memory_bandwidth": 2048,
      "interconnect": "PCIe Gen5",
      "encoders_decoders": "0, 7",
      "cuda_compute_capability": "9",
      "power_consumption": 350,
      "sources": [
         "https://getdeploying.com/reference/cloud-gpu/nvidia-h100",
         "https://www.techpowerup.com/gpu-specs/h100-pcie-80-gb.c3899",
         "https://developer.nvidia.com/video-encode-and-decode-gpu-support-matrix-new"
      ]
   },
   "h100": {
      "name": "H100",
      "fp64": 25.6,
      "fp64_tensor_core": 51,
      "fp32": 51.2,
      "tf32_tensor_core": null,
      "tf32_tensor_core_sparsity": 756,
      "fp16": 204.9,
      "fp16_tensor_core": null,
      "fp16_tensor_core_sparsity": null,
      "bf16": null,
      "bf16_tensor_core": null,
      "bf16_tensor_core_sparsity": 1513,
      "fp8": 0,
      "fp8_tensor_core": null,
      "fp4": 0,
      "fp4_tensor_core": 0,
      "fp8_tensor_core_sparsity": 3026,
      "int8": null,
      "int8_tensor_core": null,
      "int8_tensor_core_sparsity": 3026,
      "int4": 0,
      "int4_tensor_core": null,
      "int4_tensor_core_sparsity": null,
      "manufacturer": "NVIDIA",
      "architecture": "Hopper",
      "nvidia_rt_cores": null,
      "nvidia_rt_cores_generation": null,
      "nvidia_tensor_cores": 456,
      "nvidia_tensor_cores_generation": 4,
      "nvidia_cuda_cores": 14592,
      "gpu_memory": 80,
      "memory_bandwidth": 2048,
      "interconnect": "PCIe Gen5",
      "encoders_decoders": "0, 7",
      "cuda_compute_capability": "9",
      "power_consumption": 350,
      "sources": [
         "https://getdeploying.com/reference/cloud-gpu/nvidia-h100",
         "https://www.techpowerup.com/gpu-specs/h100-pcie-80-gb.c3899",
         "https://developer.nvidia.com/video-encode-and-decode-gpu-support-matrix-new"
      ]
   },
   "l40s": {
      "name": "L40S",
      "fp64": 1.4,
      "fp64_tensor_core": null,
      "fp32": 91.6,
      "tf32_tensor_core": 183,
      "tf32_tensor_core_sparsity": 366,
      "fp16": 91.6,
      "fp16_tensor_core": 362,
      "fp16_tensor_core_sparsity": 733,
      "bf16": null,
      "bf16_tensor_core": 362,
      "bf16_tensor_core_sparsity": 733,
      "fp8": 0,
      "fp8_tensor_core": 733,
      "fp8_tensor_core_sparsity": 1466,
      "fp4": 0,
      "fp4_tensor_core": 0,
      "int8": null,
      "int8_tensor_core": 733,
      "int8_tensor_core_sparsity": 1466,
      "int4": 0,
      "int4_tensor_core": 733,
      "int4_tensor_core_sparsity": 1466,
      "manufacturer": "NVIDIA",
      "architecture": "Ada Lovelace",
      "nvidia_rt_cores": 142,
      "nvidia_rt_cores_generation": 3,
      "nvidia_tensor_cores": 568,
      "nvidia_tensor_cores_generation": 4,
      "nvidia_cuda_cores": 18176,
      "gpu_memory": 48,
      "memory_bandwidth": 864,
      "interconnect": "PCIe Gen4",
      "encoders_decoders": "3, 3",
      "cuda_compute_capability": "8.9",
      "power_consumption": 300,
      "sources": [
         "https://resources.nvidia.com/en-us-l40s/l40s-datasheet-28413",
         "https://www.techpowerup.com/gpu-specs/l40s.c4173"
      ]
   },
   "l4": {
      "name": "L4",
      "fp64": 0.5,
      "fp64_tensor_core": null,
      "fp32": 30.3,
      "tf32_tensor_core": 60,
      "tf32_tensor_core_sparsity": 120,
      "fp16": 30.3,
      "fp16_tensor_core": 121,
      "fp16_tensor_core_sparsity": 242,
      "bf16": null,
      "bf16_tensor_core": 121,
      "bf16_tensor_core_sparsity": 242,
      "fp8": 0,
      "fp8_tensor_core": 242,
      "fp8_tensor_core_sparsity": 485,
      "fp4": 0,
      "fp4_tensor_core": 0,
      "int8": null,
      "int8_tensor_core": 242,
      "int8_tensor_core_sparsity": 485,
      "int4": 0,
      "int4_tensor_core": null,
      "int4_tensor_core_sparsity": null,
      "manufacturer": "NVIDIA",
      "architecture": "Ada Lovelace",
      "nvidia_rt_cores": 60,
      "nvidia_rt_cores_generation": 3,
      "nvidia_tensor_cores": 240,
      "nvidia_tensor_cores_generation": 4,
      "nvidia_cuda_cores": 7424,
      "gpu_memory": 24,
      "memory_bandwidth": 300,
      "interconnect": "PCIe Gen4",
      "encoders_decoders": "2, 4",
      "cuda_compute_capability": "8.9",
      "power_consumption": 72,
      "sources": [
         "https://resources.nvidia.com/en-us-data-center-overview/l4-gpu-datasheet",
         "https://www.techpowerup.com/gpu-specs/l4.c4091"
      ]
   },
   "a100_pcie_40gb": {
      "name": "A100 PCIe 40GB",
      "fp64": 9.7,
      "fp64_tensor_core": 19.5,
      "fp32": 19.5,
      "tf32_tensor_core": 156,
      "tf32_tensor_core_sparsity": 312,
      "fp16": 78,
      "fp16_tensor_core": 312,
      "fp16_tensor_core_sparsity": 624,
      "bf16": null,
      "bf16_tensor_core": 312,
      "bf16_tensor_core_sparsity": 624,
      "fp8": 0,
      "fp8_tensor_core": 0,
      "fp8_tensor_core_sparsity": 0,
      "fp4": 0,
      "fp4_tensor_core": 0,
      "int8": null,
      "int8_tensor_core": 624,
      "int8_tensor_core_sparsity": 1248,
      "int4": 0,
      "int4_tensor_core": null,
      "int4_tensor_core_sparsity": null,
      "manufacturer": "NVIDIA",
      "architecture": "Ampere",
      "nvidia_rt_cores": null,
      "nvidia_rt_cores_generation": null,
      "nvidia_tensor_cores": 432,
      "nvidia_tensor_cores_generation": 3,
      "nvidia_cuda_cores": 6912,
      "gpu_memory": 40,
      "memory_bandwidth": 1555,
      "interconnect": "PCIe Gen4",
      "encoders_decoders": "0, 5",
      "cuda_compute_capability": "8.0",
      "power_consumption": 250,
      "sources": [
         "https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-us-nvidia-1758950-r4-web.pdf"
      ]
   },
   "a100_pcie_80gb": {
      "name": "A100 PCIe 80GB",
      "fp64": 9.7,
      "fp64_tensor_core": 19.5,
      "fp32": 19.5,
      "tf32_tensor_core": 156,
      "tf32_tensor_core_sparsity": 312,
      "fp16": 78,
      "fp16_tensor_core": 312,
      "fp16_tensor_core_sparsity": 624,
      "bf16": null,
      "bf16_tensor_core": 312,
      "bf16_tensor_core_sparsity": 624,
      "fp8": 0,
      "fp8_tensor_core": 0,
      "fp8_tensor_core_sparsity": 0,
      "fp4": 0,
      "fp4_tensor_core": 0,
      "int8": null,
      "int8_tensor_core": 624,
      "int8_tensor_core_sparsity": 1248,
      "int4": 0,
      "int4_tensor_core": null,
      "int4_tensor_core_sparsity": null,
      "manufacturer": "NVIDIA",
      "architecture": "Ampere",
      "nvidia_rt_cores": null,
      "nvidia_rt_cores_generation": null,
      "nvidia_tensor_cores": 432,
      "nvidia_tensor_cores_generation": 3,
      "nvidia_cuda_cores": 6912,
      "gpu_memory": 80,
      "memory_bandwidth": 1935,
      "interconnect": "PCIe Gen4",
      "encoders_decoders": "0, 5",
      "cuda_compute_capability": "8",
      "power_consumption": 300,
      "sources": [
         "https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-us-nvidia-1758950-r4-web.pdf",
         "https://www.techpowerup.com/gpu-specs/a100-pcie-80-gb.c3821",
         "https://developer.nvidia.com/video-encode-and-decode-gpu-support-matrix-new"
      ]
   },
   "a100_sxm4_40gb": {
      "name": "A100 SXM4 40GB",
      "fp64": 9.7,
      "fp64_tensor_core": 19.5,
      "fp32": 19.5,
      "tf32_tensor_core": 156,
      "tf32_tensor_core_sparsity": 312,
      "fp16": 78,
      "fp16_tensor_core": 312,
      "fp16_tensor_core_sparsity": 624,
      "bf16": null,
      "bf16_tensor_core": 312,
      "bf16_tensor_core_sparsity": 624,
      "fp8": 0,
      "fp8_tensor_core": 0,
      "fp8_tensor_core_sparsity": 0,
      "fp4": 0,
      "fp4_tensor_core": 0,
      "int8": null,
      "int8_tensor_core": 624,
      "int8_tensor_core_sparsity": 1248,
      "int4": 0,
      "int4_tensor_core": null,
      "int4_tensor_core_sparsity": null,
      "manufacturer": "NVIDIA",
      "architecture": "Ampere",
      "nvidia_rt_cores": null,
      "nvidia_rt_cores_generation": null,
      "nvidia_tensor_cores": 432,
      "nvidia_tensor_cores_generation": 3,
      "nvidia_cuda_cores": 6912,
      "gpu_memory": 40,
      "memory_bandwidth": 1555,
      "interconnect": "NVLink",
      "encoders_decoders": "0, 5",
      "cuda_compute_capability": "8.0",
      "power_consumption": 400,
      "sources": [
         "https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-us-nvidia-1758950-r4-web.pdf"
      ]
   },
   "a100_sxm4_80gb": {
      "name": "A100 SXM4 80GB",
      "fp64": 9.7,
      "fp64_tensor_core": 19.5,
      "fp32": 19.5,
      "tf32_tensor_core": 156,
      "tf32_tensor_core_sparsity": 312,
      "fp16": 78,
      "fp16_tensor_core": 312,
      "fp16_tensor_core_sparsity": 624,
      "bf16": null,
      "bf16_tensor_core": 312,
      "bf16_tensor_core_sparsity": 624,
      "fp8": 0,
      "fp8_tensor_core": 0,
      "fp8_tensor_core_sparsity": 0,
      "fp4": 0,
      "fp4_tensor_core": 0,
      "int8": null,
      "int8_tensor_core": 624,
      "int8_tensor_core_sparsity": 1248,
      "int4": 0,
      "int4_tensor_core": null,
      "int4_tensor_core_sparsity": null,
      "manufacturer": "NVIDIA",
      "architecture": "Ampere",
      "nvidia_rt_cores": null,
      "nvidia_rt_cores_generation": null,
      "nvidia_tensor_cores": 432,
      "nvidia_tensor_cores_generation": 3,
      "nvidia_cuda_cores": 6912,
      "gpu_memory": 80,
      "memory_bandwidth": 2039,
      "interconnect": "NVLink",
      "encoders_decoders": "0, 5",
      "cuda_compute_capability": "8",
      "power_consumption": 400,
      "sources": [
         "https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-us-nvidia-1758950-r4-web.pdf",
         "https://www.techpowerup.com/gpu-specs/a100-pcie-80-gb.c3821",
         "https://developer.nvidia.com/video-encode-and-decode-gpu-support-matrix-new"
      ]
   },
   "a10": {
      "name": "A10",
      "fp64": 1,
      "fp64_tensor_core": null,
      "fp32": 31.2,
      "tf32_tensor_core": 62.5,
      "tf32_tensor_core_sparsity": 125,
      "fp16": 31.2,
      "fp16_tensor_core": null,
      "fp16_tensor_core_sparsity": null,
      "bf16": null,
      "bf16_tensor_core": 125,
      "bf16_tensor_core_sparsity": 250,
      "fp8": 0,
      "fp8_tensor_core": 0,
      "fp8_tensor_core_sparsity": 0,
      "fp4": 0,
      "fp4_tensor_core": 0,
      "int8": null,
      "int8_tensor_core": 250,
      "int8_tensor_core_sparsity": 500,
      "int4": 0,
      "int4_tensor_core": 500,
      "int4_tensor_core_sparsity": 1000,
      "manufacturer": "NVIDIA",
      "architecture": "Ampere",
      "nvidia_rt_cores": 72,
      "nvidia_rt_cores_generation": 2,
      "nvidia_tensor_cores": 288,
      "nvidia_tensor_cores_generation": 3,
      "nvidia_cuda_cores": 9216,
      "gpu_memory": 24,
      "memory_bandwidth": 600,
      "interconnect": "PCIe Gen4",
      "encoders_decoders": "1, 2",
      "cuda_compute_capability": "8.6",
      "power_consumption": 150,
      "sources": [
         "https://resources.nvidia.com/en-us-gpu/a10-datasheet-nvidia",
         "https://www.techpowerup.com/gpu-specs/a10-pcie.c3793",
         "https://developer.nvidia.com/video-encode-and-decode-gpu-support-matrix-new"
      ]
   },
   "t4": {
      "name": "T4",
      "fp64": null,
      "fp64_tensor_core": 0,
      "fp32": 8.1,
      "tf32_tensor_core": 0,
      "tf32_tensor_core_sparsity": 0,
      "fp16": 65,
      "fp16_tensor_core": null,
      "fp16_tensor_core_sparsity": null,
      "bf16": 0,
      "bf16_tensor_core": 0,
      "bf16_tensor_core_sparsity": 0,
      "fp8": 0,
      "fp8_tensor_core": 0,
      "fp8_tensor_core_sparsity": 0,
      "fp4": 0,
      "fp4_tensor_core": 0,
      "int8": 130,
      "int8_tensor_core": null,
      "int8_tensor_core_sparsity": null,
      "int4": 0,
      "int4_tensor_core": 260,
      "int4_tensor_core_sparsity": null,
      "manufacturer": "NVIDIA",
      "architecture": "Turing",
      "nvidia_rt_cores": null,
      "nvidia_rt_cores_generation": null,
      "nvidia_tensor_cores": 320,
      "nvidia_tensor_cores_generation": 2,
      "nvidia_cuda_cores": 2560,
      "gpu_memory": 16,
      "memory_bandwidth": 300,
      "interconnect": "PCIe Gen3",
      "encoders_decoders": "1, 2",
      "cuda_compute_capability": "7.5",
      "power_consumption": 70,
      "sources": [
         "https://getdeploying.com/reference/cloud-gpu/nvidia-t4",
         "https://developer.nvidia.com/video-encode-and-decode-gpu-support-matrix-new",
         "https://www.nvidia.com/content/dam/en-zz/Solutions/design-visualization/solutions/resources/documents1/Datasheet_NVIDIA_T4_Virtualization.pdf"
      ]
   },
   "quadro_rtx_5000": {
      "name": "Quadro RTX 5000",
      "fp64": 0.3,
      "fp64_tensor_core": 0,
      "fp32": 11.2,
      "tf32_tensor_core": 0,
      "tf32_tensor_core_sparsity": 0,
      "fp16": 22.3,
      "fp16_tensor_core": null,
      "fp16_tensor_core_sparsity": null,
      "bf16": 0,
      "bf16_tensor_core": 0,
      "bf16_tensor_core_sparsity": 0,
      "fp8": 0,
      "fp8_tensor_core": 0,
      "fp8_tensor_core_sparsity": 0,
      "fp4": 0,
      "fp4_tensor_core": 0,
      "int8": null,
      "int8_tensor_core": null,
      "int8_tensor_core_sparsity": null,
      "int4": 0,
      "int4_tensor_core": null,
      "int4_tensor_core_sparsity": null,
      "manufacturer": "NVIDIA",
      "architecture": "Turing",
      "nvidia_rt_cores": 48,
      "nvidia_rt_cores_generation": null,
      "nvidia_tensor_cores": 384,
      "nvidia_tensor_cores_generation": 2,
      "nvidia_cuda_cores": 3072,
      "gpu_memory": 16,
      "memory_bandwidth": 448,
      "interconnect": "PCIe Gen3",
      "encoders_decoders": "1, 2",
      "cuda_compute_capability": "7.5",
      "power_consumption": 230,
      "sources": [
         "https://www.nvidia.com/content/dam/en-zz/Solutions/design-visualization/quadro-product-literature/quadro-rtx-5000-data-sheet-us-nvidia-704120-r4-web.pdf",
         "https://www.techpowerup.com/gpu-specs/quadro-rtx-5000.c3308"
      ]
   },
   "v100_pcie": {
      "name": "V100 PCIe",
      "fp64": 7.1,
      "fp64_tensor_core": 0,
      "fp32": 14.1,
      "tf32_tensor_core": 112,
      "tf32_tensor_core_sparsity": 0,
      "fp16": 28.3,
      "fp16_tensor_core": 112,
      "fp16_tensor_core_sparsity": null,
      "bf16": 0,
      "bf16_tensor_core": 0,
      "bf16_tensor_core_sparsity": 0,
      "fp8": 0,
      "fp8_tensor_core": 0,
      "fp8_tensor_core_sparsity": 0,
      "fp4": 0,
      "fp4_tensor_core": 0,
      "int8": null,
      "int8_tensor_core": 0,
      "int8_tensor_core_sparsity": 0,
      "int4": 0,
      "int4_tensor_core": 0,
      "int4_tensor_core_sparsity": 0,
      "manufacturer": "NVIDIA",
      "architecture": "Volta",
      "nvidia_rt_cores": 0,
      "nvidia_tensor_cores": 640,
      "nvidia_tensor_cores_generation": 1,
      "nvidia_cuda_cores": 5120,
      "gpu_memory": "16/32",
      "memory_bandwidth": 900,
      "interconnect": "PCIe Gen3",
      "encoders_decoders": "3, 1",
      "cuda_compute_capability": "7",
      "power_consumption": 250,
      "sources": [
         "https://images.nvidia.com/content/technologies/volta/pdf/volta-v100-datasheet-update-us-1165301-r5.pdf",
         "https://www.techpowerup.com/gpu-specs/tesla-v100-pcie-32-gb.c3184",
         "https://developer.nvidia.com/video-encode-and-decode-gpu-support-matrix-new"
      ]
   },
   "v100_sxm2": {
      "name": "V100 SXM2",
      "fp64": 7.8,
      "fp64_tensor_core": 0,
      "fp32": 15.7,
      "tf32_tensor_core": 125,
      "tf32_tensor_core_sparsity": 0,
      "fp16": 31.3,
      "fp16_tensor_core": 125,
      "fp16_tensor_core_sparsity": null,
      "bf16": 0,
      "bf16_tensor_core": 0,
      "bf16_tensor_core_sparsity": 0,
      "fp8": 0,
      "fp8_tensor_core": 0,
      "fp8_tensor_core_sparsity": 0,
      "fp4": 0,
      "fp4_tensor_core": 0,
      "int8": null,
      "int8_tensor_core": 0,
      "int8_tensor_core_sparsity": 0,
      "int4": 0,
      "int4_tensor_core": 0,
      "int4_tensor_core_sparsity": 0,
      "manufacturer": "NVIDIA",
      "architecture": "Volta",
      "nvidia_rt_cores": 0,
      "nvidia_tensor_cores": 640,
      "nvidia_tensor_cores_generation": 1,
      "nvidia_cuda_cores": 5120,
      "gpu_memory": "16/32",
      "memory_bandwidth": 900,
      "interconnect": "NVLink",
      "encoders_decoders": "3, 1",
      "cuda_compute_capability": "7",
      "power_consumption": 300,
      "sources": [
         "https://images.nvidia.com/content/technologies/volta/pdf/volta-v100-datasheet-update-us-1165301-r5.pdf",
         "https://www.techpowerup.com/gpu-specs/tesla-v100-sxm2-16-gb.c3018",
         "https://www.techpowerup.com/gpu-specs/tesla-v100-sxm2-32-gb.c3183",
         "https://developer.nvidia.com/video-encode-and-decode-gpu-support-matrix-new"
      ]
   },
   "v100s_pcie": {
      "name": "V100S PCIe",
      "fp64": 8.2,
      "fp64_tensor_core": 0,
      "fp32": 16.4,
      "tf32_tensor_core": 0,
      "tf32_tensor_core_sparsity": 0,
      "fp16": 32.8,
      "fp16_tensor_core": 130,
      "fp16_tensor_core_sparsity": null,
      "bf16": 0,
      "bf16_tensor_core": 0,
      "bf16_tensor_core_sparsity": 0,
      "fp8": 0,
      "fp8_tensor_core": 0,
      "fp8_tensor_core_sparsity": 0,
      "fp4": 0,
      "fp4_tensor_core": 0,
      "int8": null,
      "int8_tensor_core": 0,
      "int8_tensor_core_sparsity": 0,
      "int4": 0,
      "int4_tensor_core": 0,
      "int4_tensor_core_sparsity": 0,
      "manufacturer": "NVIDIA",
      "architecture": "Volta",
      "nvidia_rt_cores": 0,
      "nvidia_tensor_cores": 640,
      "nvidia_tensor_cores_generation": 1,
      "nvidia_cuda_cores": 5120,
      "gpu_memory": 32,
      "memory_bandwidth": 1134,
      "interconnect": "PCIe Gen3",
      "encoders_decoders": "3, 1",
      "cuda_compute_capability": "7",
      "power_consumption": 250,
      "sources": [
         "https://images.nvidia.com/content/technologies/volta/pdf/volta-v100-datasheet-update-us-1165301-r5.pdf",
         "https://www.techpowerup.com/gpu-specs/tesla-v100s-pcie-32-gb.c3584",
         "https://developer.nvidia.com/video-encode-and-decode-gpu-support-matrix-new"
      ]
   }
}
